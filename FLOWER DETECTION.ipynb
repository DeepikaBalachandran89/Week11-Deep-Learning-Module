{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ad58e9-15aa-4924-a25f-b8ba96ed295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be9046b-7822-4e69-bec5-6348d7d668a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'E:\\Hope\\AI Course Tamil\\Week11-Deep Learning Module\\Flower Detection\\Dataset'\n",
    "img_size = 180\n",
    "batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37186273-e2df-4ebc-b803-e01dae293058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4318 files belonging to 5 classes.\n",
      "Using 3455 files for training.\n",
      "Found 4318 files belonging to 5 classes.\n",
      "Using 863 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory( base_dir,\n",
    "                                                       seed = 123,\n",
    "                                                       validation_split=0.2,\n",
    "                                                       subset = 'training',\n",
    "                                                       batch_size=batch,\n",
    "                                                       image_size=(img_size,img_size))\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory( base_dir,\n",
    "                                                       seed = 123,\n",
    "                                                       validation_split=0.2,\n",
    "                                                       subset = 'validation',\n",
    "                                                       batch_size=batch,\n",
    "                                                       image_size=(img_size,img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2c5f5a-406a-410e-ae78-30e1b7aba850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_names = train_ds.class_names\n",
    "flower_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd81a9a-1437-43a5-be16-702898edce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c46051-68f5-40c3-bd98-2776af29d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a074937-83ee-4dfa-9cbe-041944f6b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69708963-3218-4680-8b44-652e9c62576b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = Sequential([\n",
    "    layers.RandomFlip(\"horizontal\", input_shape = (img_size,img_size,3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad3cc67-978a-43d7-a41b-501746dbd5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Rescaling(1./255),\n",
    "    Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "824e5fe2-d64d-4b73-b38d-d0bbff80a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7511f3b2-cca2-4b2c-8a59-843e8b60d604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 180, 180, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 45, 45, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3965056   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,989,285\n",
      "Trainable params: 3,989,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ce2cdd6-3bc6-4130-b8ff-f44a3862ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "108/108 [==============================] - 92s 711ms/step - loss: 1.3628 - accuracy: 0.4113 - val_loss: 1.1191 - val_accuracy: 0.5377\n",
      "Epoch 2/15\n",
      "108/108 [==============================] - 79s 728ms/step - loss: 1.0823 - accuracy: 0.5705 - val_loss: 1.0300 - val_accuracy: 0.5910\n",
      "Epoch 3/15\n",
      "108/108 [==============================] - 79s 730ms/step - loss: 0.9776 - accuracy: 0.6211 - val_loss: 0.9642 - val_accuracy: 0.6408\n",
      "Epoch 4/15\n",
      "108/108 [==============================] - 76s 708ms/step - loss: 0.9249 - accuracy: 0.6428 - val_loss: 0.9880 - val_accuracy: 0.6327\n",
      "Epoch 5/15\n",
      "108/108 [==============================] - 78s 724ms/step - loss: 0.8540 - accuracy: 0.6590 - val_loss: 0.8713 - val_accuracy: 0.6489\n",
      "Epoch 6/15\n",
      "108/108 [==============================] - 75s 698ms/step - loss: 0.8086 - accuracy: 0.6831 - val_loss: 0.8694 - val_accuracy: 0.6721\n",
      "Epoch 7/15\n",
      "108/108 [==============================] - 79s 733ms/step - loss: 0.7762 - accuracy: 0.6883 - val_loss: 0.8884 - val_accuracy: 0.6674\n",
      "Epoch 8/15\n",
      "108/108 [==============================] - 95s 884ms/step - loss: 0.7433 - accuracy: 0.7129 - val_loss: 0.8699 - val_accuracy: 0.6640\n",
      "Epoch 9/15\n",
      "108/108 [==============================] - 100s 927ms/step - loss: 0.7087 - accuracy: 0.7242 - val_loss: 0.7590 - val_accuracy: 0.7184\n",
      "Epoch 10/15\n",
      "108/108 [==============================] - 95s 876ms/step - loss: 0.6509 - accuracy: 0.7473 - val_loss: 0.8780 - val_accuracy: 0.6848\n",
      "Epoch 11/15\n",
      "108/108 [==============================] - 85s 782ms/step - loss: 0.6394 - accuracy: 0.7554 - val_loss: 0.8913 - val_accuracy: 0.6640\n",
      "Epoch 12/15\n",
      "108/108 [==============================] - 79s 729ms/step - loss: 0.6106 - accuracy: 0.7725 - val_loss: 0.8656 - val_accuracy: 0.6802\n",
      "Epoch 13/15\n",
      "108/108 [==============================] - 92s 851ms/step - loss: 0.5584 - accuracy: 0.7876 - val_loss: 1.1568 - val_accuracy: 0.6315\n",
      "Epoch 14/15\n",
      "108/108 [==============================] - 99s 916ms/step - loss: 0.5382 - accuracy: 0.7936 - val_loss: 0.8158 - val_accuracy: 0.7126\n",
      "Epoch 15/15\n",
      "108/108 [==============================] - 80s 740ms/step - loss: 0.4960 - accuracy: 0.8078 - val_loss: 0.7605 - val_accuracy: 0.7231\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=15, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f54bb5-cadc-462f-83b6-a000c06474fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images(image_path):\n",
    "    input_image = tf.keras.utils.load_img(image_path, target_size=(180,180))\n",
    "    input_image_array = tf.keras.utils.img_to_array(input_image)\n",
    "    input_image_exp_dim = tf.expand_dims(input_image_array,0)\n",
    "\n",
    "    predictions = model.predict(input_image_exp_dim)\n",
    "    result = tf.nn.softmax(predictions[0])\n",
    "    outcome = 'The Image belongs to ' + flower_names[np.argmax(result)] + ' with a score of '+ str(np.max(result)*100)\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "142a9654-f338-4a63-9761-e2f68540fb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Image belongs to rose with a score of 85.52783727645874'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_images('sample/rose.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73db3dba-2544-4496-b806-0b1aa2ccaf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model \n",
    "model.save('Flower_recognition_Model.h5') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2428e5-4b2f-4e7d-ac60-a059446dc4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9000083-2578-4b97-9cdb-99fa89d5c0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162ae7c-e6cf-409b-a670-821a7dcf4da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7763e5ca-483d-42b0-8eb4-2141808e1819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 552ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load your pre-trained model\n",
    "model = tf.keras.models.load_model('Flower_recognition_Model.h5')\n",
    "\n",
    "def classify_images(image_path):\n",
    "    input_image = tf.keras.utils.load_img(image_path, target_size=(180,180))\n",
    "    input_image_array = tf.keras.utils.img_to_array(input_image)\n",
    "    input_image_exp_dim = tf.expand_dims(input_image_array,0)\n",
    "\n",
    "    predictions = model.predict(input_image_exp_dim)\n",
    "    result = tf.nn.softmax(predictions[0])\n",
    "    outcome = 'The Image belongs to ' + flower_names[np.argmax(result)] + ' with a score of '+ str(np.max(result)*100)\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(input_image_array.astype(np.uint8))\n",
    "    plt.title(outcome)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return outcome\n",
    "\n",
    "flower_names = ['Daisy', 'Dandelion', 'Rose', 'Sunflower', 'Tulip']\n",
    "\n",
    "outcome = classify_images('sample/rose.jpg')\n",
    "print(outcome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe841b9-1504-48b7-a8bf-48342b66e569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
